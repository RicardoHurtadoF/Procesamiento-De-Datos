{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fa6cb21-c01d-46f6-ad5e-c6e211365813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Autor:R.** Hurtado                  \n",
    "\n",
    "**Materia:** Procesamiento de Datos \n",
    "                            \n",
    "**Topico:** Introduccion a PySpark en el Ambiente Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a12cae4-efed-4cf7-86b7-80474528a6dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e30a9b59-abc8-4f78-b86a-d7e74f069cca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1443871951728651#setting/sparkui/0217-122501-9brqzzoe/driver-5176961274189238277\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=1443871951728651#setting/sparkui/0217-122501-9brqzzoe/driver-5176961274189238277\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d37c5f72-977d-4659-aed3-54b9f0fd4238",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dfeeba2-6ee1-413e-b3e8-81a619471cfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[51]: ['id',\n 'gender',\n 'age',\n 'hypertension',\n 'heart_disease',\n 'ever_married',\n 'work_type',\n 'Residence_type',\n 'avg_glucose_level',\n 'bmi',\n 'smoking_status',\n 'stroke']"
     ]
    }
   ],
   "source": [
    "df00 = spark.read.table(\"stroke_pyspark_2_csv\")\n",
    "df00.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b033a70d-961a-4645-8c6f-0077fee65e83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n|   id|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level| bmi| smoking_status|stroke|\n+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n| 9046|  Male|67.0|           0|            1|         Yes|      Private|         Urban|           228.69|36.6|formerly smoked|     1|\n|51676|Female|61.0|           0|            0|         Yes|Self-employed|         Rural|           202.21| N/A|   never smoked|     1|\n|31112|  Male|80.0|           0|            1|         Yes|      Private|         Rural|           105.92|32.5|   never smoked|     1|\n|60182|Female|49.0|           0|            0|         Yes|      Private|         Urban|           171.23|34.4|         smokes|     1|\n| 1665|Female|79.0|           1|            0|         Yes|Self-employed|         Rural|           174.12|  24|   never smoked|     1|\n|56669|  Male|81.0|           0|            0|         Yes|      Private|         Urban|           186.21|  29|formerly smoked|     1|\n|53882|  Male|74.0|           1|            1|         Yes|      Private|         Rural|            70.09|27.4|   never smoked|     1|\n|10434|Female|69.0|           0|            0|          No|      Private|         Urban|            94.39|22.8|   never smoked|     1|\n|27419|Female|59.0|           0|            0|         Yes|      Private|         Rural|            76.15| N/A|        Unknown|     1|\n|60491|Female|78.0|           0|            0|         Yes|      Private|         Urban|            58.57|24.2|        Unknown|     1|\n+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df00.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14528135-5606-4ca1-bbe9-fd411b78dae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- gender: string (nullable = true)\n |-- age: double (nullable = true)\n |-- hypertension: integer (nullable = true)\n |-- heart_disease: integer (nullable = true)\n |-- ever_married: string (nullable = true)\n |-- work_type: string (nullable = true)\n |-- Residence_type: string (nullable = true)\n |-- avg_glucose_level: double (nullable = true)\n |-- bmi: double (nullable = true)\n |-- smoking_status: string (nullable = true)\n |-- stroke: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df01 = df00.withColumn(\"age\", df00.age.cast(\"int\"))\n",
    "df01 = df00.withColumn(\"bmi\", df00.bmi.cast(\"double\"))\n",
    "df01.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0e4d9aa-51bb-4fda-86ac-c0c4b8df5d3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n|   id|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level| bmi| smoking_status|stroke|\n+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n| 9046|  Male|67.0|           0|            1|         Yes|      Private|         Urban|           228.69|36.6|formerly smoked|     1|\n|51676|Female|61.0|           0|            0|         Yes|Self-employed|         Rural|           202.21|null|   never smoked|     1|\n|31112|  Male|80.0|           0|            1|         Yes|      Private|         Rural|           105.92|32.5|   never smoked|     1|\n|60182|Female|49.0|           0|            0|         Yes|      Private|         Urban|           171.23|34.4|         smokes|     1|\n| 1665|Female|79.0|           1|            0|         Yes|Self-employed|         Rural|           174.12|24.0|   never smoked|     1|\n|56669|  Male|81.0|           0|            0|         Yes|      Private|         Urban|           186.21|29.0|formerly smoked|     1|\n|53882|  Male|74.0|           1|            1|         Yes|      Private|         Rural|            70.09|27.4|   never smoked|     1|\n|10434|Female|69.0|           0|            0|          No|      Private|         Urban|            94.39|22.8|   never smoked|     1|\n|27419|Female|59.0|           0|            0|         Yes|      Private|         Rural|            76.15|null|        Unknown|     1|\n|60491|Female|78.0|           0|            0|         Yes|      Private|         Urban|            58.57|24.2|        Unknown|     1|\n+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df01.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59fa9783-8d6a-4aee-b20a-bce4b8ac3ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "REVISION DE DATOS NULOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a699ef5c-a60d-40cb-9475-ef5cc736dad4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n| id|gender|age|hypertension|heart_disease|ever_married|work_type|Residence_type|avg_glucose_level|bmi|smoking_status|stroke|\n+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n|  0|     0|  0|           0|            0|           0|        0|             0|                0|201|             0|     0|\n+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df01.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df01.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eea4fd19-9c6f-4280-9de5-ef3be6cac94e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1850934813616288>:3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m### promedio de IMC por Estrato  de Edades y female\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m avg10F \u001B[38;5;241m=\u001B[39m df01\u001B[38;5;241m.\u001B[39mwhere((col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgender\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m==\u001B[39m lit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFemale\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m10\u001B[39m)))\u001B[38;5;241m.\u001B[39mselect(mean(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbmi\u001B[39m\u001B[38;5;124m'\u001B[39m)))\u001B[38;5;241m.\u001B[39mcollect()\n",
       "\u001B[1;32m      4\u001B[0m avg20F \u001B[38;5;241m=\u001B[39m df01\u001B[38;5;241m.\u001B[39mwhere((col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgender\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m==\u001B[39m lit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFemale\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m10\u001B[39m) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m20\u001B[39m))\u001B[38;5;241m.\u001B[39mselect(mean(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbmi\u001B[39m\u001B[38;5;124m'\u001B[39m)))\u001B[38;5;241m.\u001B[39mcollect()\n",
       "\u001B[1;32m      5\u001B[0m avg30F \u001B[38;5;241m=\u001B[39m df01\u001B[38;5;241m.\u001B[39mwhere((col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgender\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m==\u001B[39m lit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFemale\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m20\u001B[39m) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m30\u001B[39m))\u001B[38;5;241m.\u001B[39mselect(mean(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbmi\u001B[39m\u001B[38;5;124m'\u001B[39m)))\u001B[38;5;241m.\u001B[39mcollect()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py:164\u001B[0m, in \u001B[0;36mtry_remote_functions.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(functions, f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/functions.py:192\u001B[0m, in \u001B[0;36mcol\u001B[0;34m(col)\u001B[0m\n",
       "\u001B[1;32m    165\u001B[0m \u001B[38;5;129m@try_remote_functions\u001B[39m\n",
       "\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcol\u001B[39m(col: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Column:\n",
       "\u001B[1;32m    167\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03m    Returns a :class:`~pyspark.sql.Column` based on the given column name.\u001B[39;00m\n",
       "\u001B[1;32m    169\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    190\u001B[0m \u001B[38;5;124;03m    Column<'x'>\u001B[39;00m\n",
       "\u001B[1;32m    191\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_invoke_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcol\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/functions.py:90\u001B[0m, in \u001B[0;36m_invoke_function\u001B[0;34m(name, *args)\u001B[0m\n",
       "\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m     89\u001B[0m jf \u001B[38;5;241m=\u001B[39m _get_jvm_function(name, SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context)\n",
       "\u001B[0;32m---> 90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Column(\u001B[43mjf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n",
       "\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n",
       "\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n",
       "\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:510\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n",
       "\u001B[1;32m    508\u001B[0m ArrayList \u001B[38;5;241m=\u001B[39m JavaClass(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjava.util.ArrayList\u001B[39m\u001B[38;5;124m\"\u001B[39m, gateway_client)\n",
       "\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n",
       "\u001B[0;32m--> 510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n",
       "\u001B[1;32m    511\u001B[0m     java_list\u001B[38;5;241m.\u001B[39madd(element)\n",
       "\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:657\u001B[0m, in \u001B[0;36mColumn.__iter__\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 657\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn is not iterable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: Column is not iterable"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-1850934813616288>:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m### promedio de IMC por Estrato  de Edades y female\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m avg10F \u001B[38;5;241m=\u001B[39m df01\u001B[38;5;241m.\u001B[39mwhere((col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgender\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m==\u001B[39m lit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFemale\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m10\u001B[39m)))\u001B[38;5;241m.\u001B[39mselect(mean(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbmi\u001B[39m\u001B[38;5;124m'\u001B[39m)))\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[1;32m      4\u001B[0m avg20F \u001B[38;5;241m=\u001B[39m df01\u001B[38;5;241m.\u001B[39mwhere((col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgender\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m==\u001B[39m lit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFemale\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m10\u001B[39m) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m20\u001B[39m))\u001B[38;5;241m.\u001B[39mselect(mean(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbmi\u001B[39m\u001B[38;5;124m'\u001B[39m)))\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[1;32m      5\u001B[0m avg30F \u001B[38;5;241m=\u001B[39m df01\u001B[38;5;241m.\u001B[39mwhere((col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgender\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m==\u001B[39m lit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFemale\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m20\u001B[39m) \u001B[38;5;241m&\u001B[39m (col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m30\u001B[39m))\u001B[38;5;241m.\u001B[39mselect(mean(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbmi\u001B[39m\u001B[38;5;124m'\u001B[39m)))\u001B[38;5;241m.\u001B[39mcollect()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py:164\u001B[0m, in \u001B[0;36mtry_remote_functions.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(functions, f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/functions.py:192\u001B[0m, in \u001B[0;36mcol\u001B[0;34m(col)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;129m@try_remote_functions\u001B[39m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcol\u001B[39m(col: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Column:\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03m    Returns a :class:`~pyspark.sql.Column` based on the given column name.\u001B[39;00m\n\u001B[1;32m    169\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;124;03m    Column<'x'>\u001B[39;00m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_invoke_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcol\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/functions.py:90\u001B[0m, in \u001B[0;36m_invoke_function\u001B[0;34m(name, *args)\u001B[0m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     89\u001B[0m jf \u001B[38;5;241m=\u001B[39m _get_jvm_function(name, SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context)\n\u001B[0;32m---> 90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Column(\u001B[43mjf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:510\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    508\u001B[0m ArrayList \u001B[38;5;241m=\u001B[39m JavaClass(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjava.util.ArrayList\u001B[39m\u001B[38;5;124m\"\u001B[39m, gateway_client)\n\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n\u001B[0;32m--> 510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n\u001B[1;32m    511\u001B[0m     java_list\u001B[38;5;241m.\u001B[39madd(element)\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:657\u001B[0m, in \u001B[0;36mColumn.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 657\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn is not iterable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\n\u001B[0;31mTypeError\u001B[0m: Column is not iterable",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: Column is not iterable",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### promedio de IMC por Estrato  de Edades y female\n",
    "\n",
    "avg10F = df01.where((col('gender' == lit('Female')) & (col('age') < 10))).select(mean(col('bmi'))).collect()\n",
    "avg20F = df01.where((col('gender') == lit('Female')) & (col('age') > 10) & (col('age') < 20)).select(mean(col('bmi'))).collect()\n",
    "avg30F = df01.where((col('gender') == lit('Female')) & (col('age') > 20) & (col('age') < 30)).select(mean(col('bmi'))).collect()\n",
    "avg40F = df01.where((col('gender') == lit('Female')) & (col('age') > 30) & (col('age') < 40)).select(mean(col('bmi'))).collect()\n",
    "avg50F = df01.where((col('gender') == lit('Female')) & (col('age') > 40) & (col('age') < 50)).select(mean(col('bmi'))).collect()\n",
    "avg60F = df01.where((col('gender') == lit('Female')) & (col('age') > 50) & (col('age') < 60)).select(mean(col('bmi'))).collect()\n",
    "avg70F = df01.where((col('gender') == lit('Female')) & (col('age') > 60) & (col('age') < 70)).select(mean(col('bmi'))).collect()\n",
    "avg80F = df01.where((col('gender') == lit('Female')) & (col('age') > 70) & (col('age') < 80)).select(mean(col('bmi'))).collect()\n",
    "avg90F = df01.where((col('gender') == lit('Female')) & (col('age') > 80) & (col('age') < 90)).select(mean(col('bmi'))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fb93333-15de-474c-a120-ab04c11d4088",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Female') & (df01['bmi'].isNull()) & (df01['age'] < 10) avg10F[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Female') & (df01['bmi'].isNull()) & (df01['age'] < 20) avg20F[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Female') & (df01['bmi'].isNull()) & (df01['age'] < 30) avg30F[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Female') & (df01['bmi'].isNull()) & (df01['age'] < 40) avg40F[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Female') & (df01['bmi'].isNull()) & (df01['age'] < 50) avg50F[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Female') & (df01['bmi'].isNull()) & (df01['age'] < 60) avg60F[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Female') & (df01['bmi'].isNull()) & (df01['age'] < 70) avg70F[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Female') & (df01['bmi'].isNull()) & (df01['age'] < 80) avg80F[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Female') & (df01['bmi'].isNull()) & (df01['age'] < 90) avg90F[0][0]).otherwise(df01['bmi']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3366925d-a289-40e8-b566-e17f618a6308",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### promedio de bmi por Estrato  de Edades y Male\n",
    "\n",
    "avg10M = df02.where((col('gender' == lit('Male')) & (col('age') < 10))).select(mean(col('bmi'))).collect()\n",
    "avg20M = df02.where((col('gender') == lit('Male')) & (col('age') > 10) & (col('age') < 20)).select(mean(col('bmi'))).collect()\n",
    "avg30M = df02.where((col('gender') == lit('Male')) & (col('age') > 20) & (col('age') < 30)).select(mean(col('bmi'))).collect()\n",
    "avg40M = df02.where((col('gender') == lit('Male')) & (col('age') > 30) & (col('age') < 40)).select(mean(col('bmi'))).collect()\n",
    "avg50M = df02.where((col('gender') == lit('Male')) & (col('age') > 40) & (col('age') < 50)).select(mean(col('bmi'))).collect()\n",
    "avg60M = df02.where((col('gender') == lit('Male')) & (col('age') > 50) & (col('age') < 60)).select(mean(col('bmi'))).collect()\n",
    "avg70M = df02.where((col('gender') == lit('Male')) & (col('age') > 60) & (col('age') < 70)).select(mean(col('bmi'))).collect()\n",
    "avg80M = df02.where((col('gender') == lit('Male')) & (col('age') > 70) & (col('age') < 80)).select(mean(col('bmi'))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a235b1c-e816-4f77-af36-b5d57d7fbc1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Male') & (df01['bmi'].isNull()) & (df01['age'] < 10) avg10M[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Male') & (df01['bmi'].isNull()) & (df01['age'] < 20) avg20M[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Male') & (df01['bmi'].isNull()) & (df01['age'] < 30) avg30M[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Male') & (df01['bmi'].isNull()) & (df01['age'] < 40) avg40M[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Male') & (df01['bmi'].isNull()) & (df01['age'] < 50) avg50M[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Male') & (df01['bmi'].isNull()) & (df01['age'] < 60) avg60M[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Male') & (df01['bmi'].isNull()) & (df01['age'] < 70) avg70M[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Male') & (df01['bmi'].isNull()) & (df01['age'] < 80) avg80M[0][0]).otherwise(df01['bmi']))\n",
    "df02 = df01.withColumn(\"bmi\", when((df01['gender'] == 'Male') & (df01['bmi'].isNull()) & (df01['age'] < 90) avg90M[0][0]).otherwise(df01['bmi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dabb0bc1-3fc4-4100-90fe-72f63828d1db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df02.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df03.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023ea404-bb55-432e-971f-8fb9e3cfb5c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rangos = [(0, 10), (10, 20), (20, 30), (30, 40), (40, 50), (50, 60), (60, 70), (70, 80), (80, 90)]\n",
    "\n",
    "def calcular_promedio_imc(df, gender, rangos):\n",
    "    promedios = {}\n",
    "    for star, end in rangos:\n",
    "        key = f'avg{end}{gender[0]}'\n",
    "        avg = df.where((col('gender') == lit('genero')) & (col('age') >= start) & (col('age') < end)).select \n",
    "        (mean(col('bmi'))).collect\n",
    "        promedios[key] = avg\n",
    "\n",
    "        return promedios\n",
    "    resultadosF = calcular_promedio_imc(df01, 'Female', rangos)\n",
    "    print(resultadosF)\n",
    "    resultadosM = calcular_promedio_imc(df01, 'Male', rangos)\n",
    "    print(resultadosF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cb830e0-7b55-4541-94e3-23e2022ce9da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c30e8f37-04d9-414f-856d-31570b3a2b75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##grafica edades\n",
    "\n",
    "clases, cantidad = df04.groupby('age').count().select('count').rdd.flatMap(lambda x: x).histogram(20)\n",
    "plt.hist8clases[:-1], bin = clases, weight = cantidad\n",
    "plt.ylabel('cantidad')\n",
    "plt.xlabel('edad')\n",
    "plt.title('histograma por edades')\n",
    "plt.legend(['age'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95d732ad-0f2a-469b-99d2-d864270c85d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##genero\n",
    "genero = df02.groupby('gender').count().select('count').rdd.flatMap(lambda x: x).collect()\n",
    "#plt.hist8clases[:-1], bin = clases, weight = cantidad\n",
    "categoria = ['mujeres', 'hombres']\n",
    "grafica = plt.bar(categoria, genero)\n",
    "grafica[0].set_color('r')\n",
    "plt.ylabel('cantidad')\n",
    "plt.xlabel('genero')\n",
    "plt.title('grafica de barras por genero')\n",
    "#plt.legend(['gender'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38e4968f-a184-4d64-a844-8d701bab9a04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##enfermedades cardiacas\n",
    "enfCardiaca = df02.groupby('heart_disease').count().select('count').rdd.flatMap(lambda x: x).collect()\n",
    "#plt.hist8clases[:-1], bin = clases, weight = cantidad\n",
    "categoria = ['si', 'no']\n",
    "grafica = plt.bar(categoria, enfCardiaca)\n",
    "grafica[0].set_color('r')\n",
    "plt.ylabel('cantidad')\n",
    "plt.xlabel('Enfermedad Cardiaca')\n",
    "plt.title('grafica de barras por Enfermedad Cardiaca')\n",
    "#plt.legend(['gender'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Hurtado_febrero_2025",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
